#!/usr/bin/env python3
"""Game Map Generator - Generate game level images from tilemaps.

Usage:
    gamemap generate <tilemap.json>     Generate an image from a tilemap
    gamemap visualize <tilemap.json>    Create tilemap visualization without generating
    gamemap overlay <image> <tilemap>   Overlay tilemap colors on an existing image
"""

import argparse
import json
import sys
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
from PIL import Image

# Terrain type to visualization color (RGB)
TERRAIN_COLORS = {
    "trees": (34, 139, 34),       # Forest green
    "grass": (124, 252, 0),       # Lawn green
    "water": (30, 144, 255),      # Dodger blue
    "path": (139, 90, 43),        # Brown
    "sand": (238, 214, 175),      # Sandy beige
    "wall": (128, 128, 128),      # Gray
    "lava": (255, 69, 0),         # Red-orange
    "snow": (255, 250, 250),      # Snow white
    "stone": (105, 105, 105),     # Dim gray
    "dirt": (139, 69, 19),        # Saddle brown
    "bridge": (160, 82, 45),      # Sienna
    "flowers": (255, 105, 180),   # Hot pink
}


def load_tilemap(path: Path) -> Tuple[str, List[str], Dict[str, str]]:
    """Load tilemap from JSON file."""
    with open(path) as f:
        data = json.load(f)
    return data["description"], data["tiles"], data["legend"]


def create_tilemap_visualization(
    tiles: List[str],
    legend: Dict[str, str],
    output_width: int,
    output_height: int,
) -> Image.Image:
    """Create a color-coded visualization of the tilemap."""
    tile_height = len(tiles)
    tile_width = len(tiles[0])

    # Create RGB image at tile resolution
    img_array = np.zeros((tile_height, tile_width, 3), dtype=np.uint8)

    for y, row in enumerate(tiles):
        for x, char in enumerate(row):
            terrain = legend.get(char, "unknown")
            color = TERRAIN_COLORS.get(terrain, (255, 0, 255))  # Magenta for unknown
            img_array[y, x] = color

    # Scale up to output resolution
    img = Image.fromarray(img_array)
    img = img.resize((output_width, output_height), Image.Resampling.NEAREST)

    return img


def create_overlay(
    image: Image.Image,
    tilemap_vis: Image.Image,
    alpha: float = 0.4,
) -> Image.Image:
    """Create an overlay of the tilemap visualization on the image."""
    image = image.convert("RGB")
    tilemap_vis = tilemap_vis.convert("RGB")
    return Image.blend(image, tilemap_vis, alpha)


def cmd_visualize(args):
    """Create tilemap visualization without generating."""
    print(f"Loading tilemap: {args.tilemap}")
    description, tiles, legend = load_tilemap(args.tilemap)

    print(f"  Description: {description}")
    print(f"  Size: {len(tiles[0])}x{len(tiles)} tiles")
    print(f"  Terrain types: {list(set(legend.values()))}")

    # Create visualization
    vis = create_tilemap_visualization(tiles, legend, args.width, args.height)

    # Determine output path
    output_path = args.output or Path(f"{args.tilemap.stem}_tilemap.png")
    vis.save(output_path)
    print(f"\nSaved: {output_path}")

    # Print color legend
    print("\nColor legend:")
    for terrain in set(legend.values()):
        color = TERRAIN_COLORS.get(terrain, (255, 0, 255))
        print(f"  {terrain}: RGB{color}")


def cmd_overlay(args):
    """Overlay tilemap colors on an existing image."""
    print(f"Loading image: {args.image}")
    image = Image.open(args.image)

    print(f"Loading tilemap: {args.tilemap}")
    description, tiles, legend = load_tilemap(args.tilemap)

    # Create visualization at image size
    vis = create_tilemap_visualization(tiles, legend, image.width, image.height)

    # Create overlay
    overlay = create_overlay(image, vis, args.alpha)

    # Determine output path
    output_path = args.output or Path(f"{args.image.stem}_overlay.png")
    overlay.save(output_path)
    print(f"\nSaved: {output_path}")


def cmd_generate(args):
    """Generate an image from a tilemap."""
    # Import heavy dependencies only when needed
    import torch
    import torch.nn.functional as F
    from diffusers import StableDiffusionXLPipeline

    # Terrain prompts
    TERRAIN_PROMPTS = {
        "trees": "dense forest with tall trees, lush green foliage",
        "grass": "lush green grass field, meadow",
        "water": "calm blue water, pond, lake surface",
        "path": "dirt path, brown walking trail",
        "sand": "sandy beach, golden sand",
        "wall": "stone wall, gray bricks",
        "lava": "molten lava, glowing orange magma",
        "snow": "white snow, snowy ground",
        "stone": "gray stone floor, rocky ground",
        "dirt": "brown dirt, soil",
        "bridge": "wooden bridge planks",
        "flowers": "colorful wildflowers in grass",
    }

    print("Game Map Generator")
    print("=" * 50)

    # Load tilemap
    print(f"\nLoading tilemap: {args.tilemap}")
    description, tiles, legend = load_tilemap(args.tilemap)
    print(f"  Description: {description}")
    print(f"  Size: {len(tiles[0])}x{len(tiles)} tiles")
    print(f"  Terrain types: {list(set(legend.values()))}")

    # Setup device
    device = "mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu"
    print(f"\nUsing device: {device}")

    # Load pipeline
    print("\nLoading SDXL pipeline...")
    use_fp32 = device == "mps"
    pipe = StableDiffusionXLPipeline.from_pretrained(
        "stabilityai/stable-diffusion-xl-base-1.0",
        torch_dtype=torch.float32 if use_fp32 else torch.float16,
        variant=None if use_fp32 else "fp16",
        use_safetensors=True,
    )
    pipe.enable_attention_slicing()
    pipe.to(device)

    # Create terrain masks
    print("\nCreating terrain masks...")
    tile_height = len(tiles)
    tile_width = len(tiles[0])

    terrain_masks_np = {}
    for char, terrain in legend.items():
        if terrain not in terrain_masks_np:
            terrain_masks_np[terrain] = np.zeros((tile_height, tile_width), dtype=np.float32)
        for y, row in enumerate(tiles):
            for x, c in enumerate(row):
                if c == char:
                    terrain_masks_np[terrain][y, x] = 1.0

    terrain_masks_np = {k: v for k, v in terrain_masks_np.items() if v.sum() > 0}

    # Upscale masks with soft edges
    terrain_masks = {}
    for terrain, mask in terrain_masks_np.items():
        mask_tensor = torch.from_numpy(mask).unsqueeze(0).unsqueeze(0)
        upscaled = F.interpolate(
            mask_tensor,
            size=(args.height, args.width),
            mode='bilinear',
            align_corners=False,
        ).squeeze()

        kernel_size = max(3, args.width // tile_width // 2)
        if kernel_size % 2 == 0:
            kernel_size += 1
        padded = F.pad(upscaled.unsqueeze(0).unsqueeze(0),
                       (kernel_size//2, kernel_size//2, kernel_size//2, kernel_size//2),
                       mode='reflect')
        blurred = F.avg_pool2d(padded, kernel_size, stride=1).squeeze()
        terrain_masks[terrain] = blurred

    # Output directory
    output_dir = args.output.parent if args.output else Path("output")
    output_dir.mkdir(exist_ok=True)

    # Save tilemap visualization
    tilemap_vis = create_tilemap_visualization(tiles, legend, args.width, args.height)
    tilemap_vis_path = output_dir / f"{args.tilemap.stem}_tilemap.png"
    tilemap_vis.save(tilemap_vis_path)
    print(f"  Saved tilemap: {tilemap_vis_path}")

    # Generate image
    print("\nGenerating image...")
    model_dtype = next(pipe.unet.parameters()).dtype
    negative_prompt = "cartoon, blurry, illustration, text, watermark, low quality"
    base_style = f"aerial view, photorealistic, top-down, game map, {description}, high detail, seamless"

    # Build prompts and masks
    prompts = []
    masks_list = []
    for terrain, mask in terrain_masks.items():
        terrain_desc = TERRAIN_PROMPTS.get(terrain, terrain)
        prompts.append(f"{terrain_desc}, {base_style}")
        masks_list.append(mask)
        coverage = mask.mean().item() * 100
        print(f"    {terrain}: {coverage:.1f}% coverage")

    # Encode prompts
    prompt_embeds_list = []
    pooled_embeds_list = []
    for prompt in prompts:
        prompt_embeds, neg_embeds, pooled, neg_pooled = pipe.encode_prompt(
            prompt=prompt, prompt_2=prompt, device=device,
            num_images_per_prompt=1, do_classifier_free_guidance=True,
            negative_prompt=negative_prompt, negative_prompt_2=negative_prompt,
        )
        prompt_embeds_list.append(torch.cat([neg_embeds, prompt_embeds], dim=0))
        pooled_embeds_list.append(torch.cat([neg_pooled, pooled], dim=0))

    # Prepare latent masks
    latent_h, latent_w = args.height // 8, args.width // 8
    mask_tensors = []
    for mask in masks_list:
        resized = F.interpolate(
            mask.unsqueeze(0).unsqueeze(0).float(),
            size=(latent_h, latent_w),
            mode='bilinear',
            align_corners=False,
        ).squeeze().to(device)
        mask_tensors.append(resized)

    mask_sum = sum(mask_tensors)
    mask_tensors = [m / (mask_sum + 1e-8) for m in mask_tensors]

    # Setup diffusion
    pipe.scheduler.set_timesteps(args.steps, device=device)
    timesteps = pipe.scheduler.timesteps

    generator = torch.Generator(device=device).manual_seed(args.seed)
    latents = torch.randn(
        (1, pipe.unet.config.in_channels, latent_h, latent_w),
        generator=generator, device=device, dtype=model_dtype,
    ) * pipe.scheduler.init_noise_sigma

    text_encoder_projection_dim = pooled_embeds_list[0].shape[-1]
    add_time_ids = pipe._get_add_time_ids(
        original_size=(args.height, args.width),
        crops_coords_top_left=(0, 0),
        target_size=(args.height, args.width),
        dtype=model_dtype,
        text_encoder_projection_dim=text_encoder_projection_dim,
    ).to(device)
    add_time_ids = torch.cat([add_time_ids, add_time_ids], dim=0)

    # Denoising loop
    for i, t in enumerate(timesteps):
        latent_model_input = torch.cat([latents] * 2)
        latent_model_input = pipe.scheduler.scale_model_input(latent_model_input, t)

        noise_preds = []
        for prompt_embeds, pooled_embeds in zip(prompt_embeds_list, pooled_embeds_list):
            noise_pred = pipe.unet(
                latent_model_input, t,
                encoder_hidden_states=prompt_embeds,
                added_cond_kwargs={"text_embeds": pooled_embeds, "time_ids": add_time_ids},
                return_dict=False,
            )[0]
            noise_preds.append(noise_pred)

        blended_pred = torch.zeros_like(noise_preds[0])
        for noise_pred, mask in zip(noise_preds, mask_tensors):
            blended_pred += noise_pred * mask.unsqueeze(0).unsqueeze(0).expand_as(noise_pred)

        noise_pred_uncond, noise_pred_cond = blended_pred.chunk(2)
        noise_pred = noise_pred_uncond + args.guidance * (noise_pred_cond - noise_pred_uncond)
        latents = pipe.scheduler.step(noise_pred, t, latents, return_dict=False)[0]

        if (i + 1) % 5 == 0:
            print(f"    Step {i + 1}/{args.steps}")

    # Decode
    latents = latents / pipe.vae.config.scaling_factor
    image = pipe.vae.decode(latents.to(pipe.vae.dtype), return_dict=False)[0]
    image = pipe.image_processor.postprocess(image, output_type="pil")[0]

    # Save outputs
    output_path = args.output or (output_dir / f"{args.tilemap.stem}_generated.png")
    image.save(output_path)
    print(f"\nSaved: {output_path}")

    overlay = create_overlay(image, tilemap_vis, 0.4)
    overlay_path = output_dir / f"{args.tilemap.stem}_overlay.png"
    overlay.save(overlay_path)
    print(f"Saved overlay: {overlay_path}")

    print("\n" + "=" * 50)
    print("Generation complete!")


def main():
    parser = argparse.ArgumentParser(
        description="Game Map Generator - Generate game level images from tilemaps",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  gamemap generate examples/forest.json
  gamemap generate examples/beach.json --seed 123 --steps 30
  gamemap visualize examples/dungeon.json -o dungeon_layout.png
  gamemap overlay output/forest_generated.png examples/forest.json
        """,
    )
    subparsers = parser.add_subparsers(dest="command", required=True)

    # Generate command
    gen_parser = subparsers.add_parser(
        "generate",
        help="Generate an image from a tilemap using AI",
        description="Generate a photorealistic game map image from a tilemap JSON file.",
    )
    gen_parser.add_argument("tilemap", type=Path, help="Path to tilemap JSON file")
    gen_parser.add_argument("-o", "--output", type=Path, help="Output image path")
    gen_parser.add_argument("--seed", type=int, default=42, help="Random seed (default: 42)")
    gen_parser.add_argument("--steps", type=int, default=25, help="Inference steps (default: 25)")
    gen_parser.add_argument("--width", type=int, default=1024, help="Output width (default: 1024)")
    gen_parser.add_argument("--height", type=int, default=768, help="Output height (default: 768)")
    gen_parser.add_argument("--guidance", type=float, default=7.5, help="Guidance scale (default: 7.5)")
    gen_parser.set_defaults(func=cmd_generate)

    # Visualize command
    vis_parser = subparsers.add_parser(
        "visualize",
        help="Create a color-coded tilemap visualization",
        description="Create a color-coded image showing terrain types from a tilemap.",
    )
    vis_parser.add_argument("tilemap", type=Path, help="Path to tilemap JSON file")
    vis_parser.add_argument("-o", "--output", type=Path, help="Output image path")
    vis_parser.add_argument("--width", type=int, default=1024, help="Output width (default: 1024)")
    vis_parser.add_argument("--height", type=int, default=768, help="Output height (default: 768)")
    vis_parser.set_defaults(func=cmd_visualize)

    # Overlay command
    overlay_parser = subparsers.add_parser(
        "overlay",
        help="Overlay tilemap colors on an existing image",
        description="Create a comparison overlay of tilemap colors on an existing image.",
    )
    overlay_parser.add_argument("image", type=Path, help="Path to existing image")
    overlay_parser.add_argument("tilemap", type=Path, help="Path to tilemap JSON file")
    overlay_parser.add_argument("-o", "--output", type=Path, help="Output image path")
    overlay_parser.add_argument("--alpha", type=float, default=0.4, help="Overlay opacity (default: 0.4)")
    overlay_parser.set_defaults(func=cmd_overlay)

    args = parser.parse_args()
    args.func(args)


if __name__ == "__main__":
    main()
