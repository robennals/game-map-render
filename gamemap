#!/usr/bin/env python3
"""Game Map Generator - Generate game level images from tilemaps.

Usage:
    gamemap generate <tilemap.json>     Generate an image from a tilemap
    gamemap visualize <tilemap.json>    Create tilemap visualization without generating
    gamemap overlay <image> <tilemap>   Overlay tilemap colors on an existing image
"""

import argparse
import json
import sys
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
from PIL import Image

# Terrain type to visualization color (RGB)
TERRAIN_COLORS = {
    "trees": (34, 139, 34),       # Forest green
    "grass": (124, 252, 0),       # Lawn green
    "water": (30, 144, 255),      # Dodger blue
    "path": (139, 90, 43),        # Brown
    "sand": (238, 214, 175),      # Sandy beige
    "wall": (128, 128, 128),      # Gray
    "lava": (255, 69, 0),         # Red-orange
    "snow": (255, 250, 250),      # Snow white
    "stone": (105, 105, 105),     # Dim gray
    "dirt": (139, 69, 19),        # Saddle brown
    "bridge": (160, 82, 45),      # Sienna
    "flowers": (255, 105, 180),   # Hot pink
}


def load_tilemap(path: Path) -> Tuple[str, List[str], Dict[str, str]]:
    """Load tilemap from JSON file."""
    with open(path) as f:
        data = json.load(f)
    return data["description"], data["tiles"], data["legend"]


def create_tilemap_visualization(
    tiles: List[str],
    legend: Dict[str, str],
    output_width: int,
    output_height: int,
) -> Image.Image:
    """Create a color-coded visualization of the tilemap."""
    tile_height = len(tiles)
    tile_width = len(tiles[0])

    # Create RGB image at tile resolution
    img_array = np.zeros((tile_height, tile_width, 3), dtype=np.uint8)

    for y, row in enumerate(tiles):
        for x, char in enumerate(row):
            terrain = legend.get(char, "unknown")
            color = TERRAIN_COLORS.get(terrain, (255, 0, 255))  # Magenta for unknown
            img_array[y, x] = color

    # Scale up to output resolution
    img = Image.fromarray(img_array)
    img = img.resize((output_width, output_height), Image.Resampling.NEAREST)

    return img


def create_overlay(
    image: Image.Image,
    tilemap_vis: Image.Image,
    alpha: float = 0.4,
) -> Image.Image:
    """Create an overlay of the tilemap visualization on the image."""
    image = image.convert("RGB")
    tilemap_vis = tilemap_vis.convert("RGB")
    return Image.blend(image, tilemap_vis, alpha)


def cmd_visualize(args):
    """Create tilemap visualization without generating."""
    print(f"Loading tilemap: {args.tilemap}")
    description, tiles, legend = load_tilemap(args.tilemap)

    print(f"  Description: {description}")
    print(f"  Size: {len(tiles[0])}x{len(tiles)} tiles")
    print(f"  Terrain types: {list(set(legend.values()))}")

    # Create visualization
    vis = create_tilemap_visualization(tiles, legend, args.width, args.height)

    # Determine output path
    output_path = args.output or Path(f"{args.tilemap.stem}_tilemap.png")
    vis.save(output_path)
    print(f"\nSaved: {output_path}")

    # Print color legend
    print("\nColor legend:")
    for terrain in set(legend.values()):
        color = TERRAIN_COLORS.get(terrain, (255, 0, 255))
        print(f"  {terrain}: RGB{color}")


def cmd_overlay(args):
    """Overlay tilemap colors on an existing image."""
    print(f"Loading image: {args.image}")
    image = Image.open(args.image)

    print(f"Loading tilemap: {args.tilemap}")
    description, tiles, legend = load_tilemap(args.tilemap)

    # Create visualization at image size
    vis = create_tilemap_visualization(tiles, legend, image.width, image.height)

    # Create overlay
    overlay = create_overlay(image, vis, args.alpha)

    # Determine output path
    output_path = args.output or Path(f"{args.image.stem}_overlay.png")
    overlay.save(output_path)
    print(f"\nSaved: {output_path}")


def cmd_generate(args):
    """Generate an image from a tilemap."""
    # Import heavy dependencies only when needed
    import torch
    import torch.nn.functional as F
    from diffusers import StableDiffusionXLPipeline

    # Terrain prompts - be specific and exclusive to avoid bleeding
    TERRAIN_PROMPTS = {
        "trees": "dense forest canopy, tall trees seen from above, green foliage, tree tops",
        "grass": "flat green grass lawn, open meadow, no trees, short grass, empty field",
        "water": "blue water surface, calm pond, lake water, reflective water",
        "path": "brown dirt path, walking trail, bare earth trail",
        "sand": "golden sand, sandy ground, beach sand, no grass",
        "wall": "gray stone wall, brick wall, stone blocks",
        "lava": "glowing orange lava, molten magma, bright orange",
        "snow": "white snow covered ground, snowy surface",
        "stone": "gray stone floor, cobblestone, rocky ground",
        "dirt": "brown dirt ground, bare soil, mud",
        "bridge": "wooden bridge planks, wooden boards",
        "flowers": "colorful wildflowers, flower field",
    }

    # Per-terrain negative prompts to prevent bleeding
    TERRAIN_NEGATIVES = {
        "grass": "trees, forest, bushes, shrubs",
        "water": "grass, land, trees",
        "sand": "grass, trees, water",
        "path": "grass, trees, water",
        "stone": "grass, trees, plants",
    }

    print("Game Map Generator")
    print("=" * 50)

    # Load tilemap
    print(f"\nLoading tilemap: {args.tilemap}")
    description, tiles, legend = load_tilemap(args.tilemap)
    print(f"  Description: {description}")
    print(f"  Size: {len(tiles[0])}x{len(tiles)} tiles")
    print(f"  Terrain types: {list(set(legend.values()))}")

    # Setup device
    if args.cpu:
        device = "cpu"
    else:
        device = "mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu"
    print(f"\nUsing device: {device}")

    # Load SDXL pipeline - good quality and prompt following
    print("\nLoading SDXL pipeline...")
    # Use float32 on MPS to avoid NaN issues
    use_fp32 = device == "mps"
    pipe = StableDiffusionXLPipeline.from_pretrained(
        "stabilityai/stable-diffusion-xl-base-1.0",
        torch_dtype=torch.float32 if use_fp32 else torch.float16,
        use_safetensors=True,
        variant=None if use_fp32 else "fp16",
    )
    pipe.enable_attention_slicing()
    pipe.to(device)

    # Create terrain masks
    print("\nCreating terrain masks...")
    tile_height = len(tiles)
    tile_width = len(tiles[0])

    terrain_masks_np = {}
    for char, terrain in legend.items():
        if terrain not in terrain_masks_np:
            terrain_masks_np[terrain] = np.zeros((tile_height, tile_width), dtype=np.float32)
        for y, row in enumerate(tiles):
            for x, c in enumerate(row):
                if c == char:
                    terrain_masks_np[terrain][y, x] = 1.0

    terrain_masks_np = {k: v for k, v in terrain_masks_np.items() if v.sum() > 0}

    # Upscale masks with soft edges
    terrain_masks = {}
    for terrain, mask in terrain_masks_np.items():
        mask_tensor = torch.from_numpy(mask).unsqueeze(0).unsqueeze(0)
        upscaled = F.interpolate(
            mask_tensor,
            size=(args.height, args.width),
            mode='bilinear',
            align_corners=False,
        ).squeeze()

        kernel_size = max(3, args.width // tile_width // 2)
        if kernel_size % 2 == 0:
            kernel_size += 1
        padded = F.pad(upscaled.unsqueeze(0).unsqueeze(0),
                       (kernel_size//2, kernel_size//2, kernel_size//2, kernel_size//2),
                       mode='reflect')
        blurred = F.avg_pool2d(padded, kernel_size, stride=1).squeeze()
        terrain_masks[terrain] = blurred

    # Output directory
    output_dir = args.output.parent if args.output else Path("output")
    output_dir.mkdir(exist_ok=True)

    # Save tilemap visualization
    tilemap_vis = create_tilemap_visualization(tiles, legend, args.width, args.height)
    tilemap_vis_path = output_dir / f"{args.tilemap.stem}_tilemap.png"
    tilemap_vis.save(tilemap_vis_path)
    print(f"  Saved tilemap: {tilemap_vis_path}")

    # Generate image
    print("\nGenerating image...")
    # Base style for all prompts
    base_style = "aerial view, photorealistic, top-down, game map, high detail, seamless"

    # Extract just lighting/mood words from description, avoid terrain words
    # Common terrain words to filter out of atmosphere
    terrain_words = {'forest', 'trees', 'grass', 'water', 'lake', 'pond', 'river',
                     'sand', 'beach', 'stone', 'rock', 'path', 'road', 'snow', 'lava'}
    desc_words = description.lower().split()
    atmosphere_words = [w for w in description.split() if w.lower().strip(',.!') not in terrain_words]
    atmosphere = ' '.join(atmosphere_words) if atmosphere_words else ""

    base_negative = "cartoon, blurry, illustration, text, watermark, low quality"

    # Build prompts and masks - put terrain content FIRST for stronger influence
    prompts = []
    negatives = []
    masks_list = []
    for terrain, mask in terrain_masks.items():
        terrain_desc = TERRAIN_PROMPTS.get(terrain, terrain)
        terrain_neg = TERRAIN_NEGATIVES.get(terrain, "")
        # Terrain first, then style, then atmosphere
        prompts.append(f"{terrain_desc}, {base_style}, {atmosphere}")
        negatives.append(f"{base_negative}, {terrain_neg}" if terrain_neg else base_negative)
        masks_list.append(mask)
        coverage = mask.mean().item() * 100
        print(f"    {terrain}: {coverage:.1f}% coverage")

    # Encode prompts for SDXL (dual text encoders)
    prompt_embeds_list = []
    pooled_embeds_list = []
    for prompt, neg in zip(prompts, negatives):
        prompt_embeds, neg_embeds, pooled, neg_pooled = pipe.encode_prompt(
            prompt=prompt, prompt_2=prompt, device=device,
            num_images_per_prompt=1, do_classifier_free_guidance=True,
            negative_prompt=neg, negative_prompt_2=neg,
        )
        prompt_embeds_list.append(torch.cat([neg_embeds, prompt_embeds], dim=0))
        pooled_embeds_list.append(torch.cat([neg_pooled, pooled], dim=0))

    # Prepare latent masks (SDXL uses 8x compression)
    latent_h, latent_w = args.height // 8, args.width // 8
    mask_tensors = []
    for mask in masks_list:
        resized = F.interpolate(
            mask.unsqueeze(0).unsqueeze(0).float(),
            size=(latent_h, latent_w),
            mode='bilinear',
            align_corners=False,
        ).squeeze().to(device)
        mask_tensors.append(resized)

    mask_sum = sum(mask_tensors)
    mask_tensors = [m / (mask_sum + 1e-8) for m in mask_tensors]

    # Setup diffusion
    model_dtype = next(pipe.unet.parameters()).dtype
    pipe.scheduler.set_timesteps(args.steps, device=device)
    timesteps = pipe.scheduler.timesteps

    generator = torch.Generator(device=device).manual_seed(args.seed)
    latents = torch.randn(
        (1, pipe.unet.config.in_channels, latent_h, latent_w),
        generator=generator, device=device, dtype=model_dtype,
    ) * pipe.scheduler.init_noise_sigma

    # SDXL additional conditioning
    text_encoder_projection_dim = pooled_embeds_list[0].shape[-1]
    add_time_ids = pipe._get_add_time_ids(
        original_size=(args.height, args.width),
        crops_coords_top_left=(0, 0),
        target_size=(args.height, args.width),
        dtype=model_dtype,
        text_encoder_projection_dim=text_encoder_projection_dim,
    ).to(device)
    add_time_ids = torch.cat([add_time_ids, add_time_ids], dim=0)

    # Denoising loop with regional prompt blending
    with torch.no_grad():
        for i, t in enumerate(timesteps):
            latent_model_input = torch.cat([latents] * 2)
            latent_model_input = pipe.scheduler.scale_model_input(latent_model_input, t)

            noise_preds = []
            for prompt_embeds, pooled_embeds in zip(prompt_embeds_list, pooled_embeds_list):
                noise_pred = pipe.unet(
                    latent_model_input, t,
                    encoder_hidden_states=prompt_embeds,
                    added_cond_kwargs={"text_embeds": pooled_embeds, "time_ids": add_time_ids},
                    return_dict=False,
                )[0]
                noise_preds.append(noise_pred.clone())

                # Clear MPS cache between forward passes
                if device == "mps":
                    torch.mps.empty_cache()

            # Blend predictions based on terrain masks
            blended_pred = torch.zeros_like(noise_preds[0])
            for noise_pred, mask in zip(noise_preds, mask_tensors):
                blended_pred += noise_pred * mask.unsqueeze(0).unsqueeze(0).expand_as(noise_pred)

            noise_pred_uncond, noise_pred_cond = blended_pred.chunk(2)
            noise_pred = noise_pred_uncond + args.guidance * (noise_pred_cond - noise_pred_uncond)
            latents = pipe.scheduler.step(noise_pred, t, latents, return_dict=False)[0]

            if (i + 1) % 5 == 0:
                print(f"    Step {i + 1}/{args.steps}")

    # Decode
    latents = latents / pipe.vae.config.scaling_factor
    with torch.no_grad():
        image = pipe.vae.decode(latents.to(pipe.vae.dtype), return_dict=False)[0]
    image = pipe.image_processor.postprocess(image.detach(), output_type="pil")[0]

    # Save outputs
    output_path = args.output or (output_dir / f"{args.tilemap.stem}_generated.png")
    image.save(output_path)
    print(f"\nSaved: {output_path}")

    overlay = create_overlay(image, tilemap_vis, 0.4)
    overlay_path = output_dir / f"{args.tilemap.stem}_overlay.png"
    overlay.save(overlay_path)
    print(f"Saved overlay: {overlay_path}")

    print("\n" + "=" * 50)
    print("Generation complete!")


def main():
    parser = argparse.ArgumentParser(
        description="Game Map Generator - Generate game level images from tilemaps",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  gamemap generate examples/forest.json
  gamemap generate examples/beach.json --seed 123 --steps 30
  gamemap visualize examples/dungeon.json -o dungeon_layout.png
  gamemap overlay output/forest_generated.png examples/forest.json
        """,
    )
    subparsers = parser.add_subparsers(dest="command", required=True)

    # Generate command
    gen_parser = subparsers.add_parser(
        "generate",
        help="Generate an image from a tilemap using AI",
        description="Generate a photorealistic game map image from a tilemap JSON file.",
    )
    gen_parser.add_argument("tilemap", type=Path, help="Path to tilemap JSON file")
    gen_parser.add_argument("-o", "--output", type=Path, help="Output image path")
    gen_parser.add_argument("--seed", type=int, default=42, help="Random seed (default: 42)")
    gen_parser.add_argument("--steps", type=int, default=25, help="Inference steps (default: 25)")
    gen_parser.add_argument("--width", type=int, default=1024, help="Output width (default: 1024)")
    gen_parser.add_argument("--height", type=int, default=768, help="Output height (default: 768)")
    gen_parser.add_argument("--guidance", type=float, default=7.5, help="Guidance scale (default: 7.5)")
    gen_parser.add_argument("--cpu", action="store_true", help="Force CPU (slower but more stable)")
    gen_parser.set_defaults(func=cmd_generate)

    # Visualize command
    vis_parser = subparsers.add_parser(
        "visualize",
        help="Create a color-coded tilemap visualization",
        description="Create a color-coded image showing terrain types from a tilemap.",
    )
    vis_parser.add_argument("tilemap", type=Path, help="Path to tilemap JSON file")
    vis_parser.add_argument("-o", "--output", type=Path, help="Output image path")
    vis_parser.add_argument("--width", type=int, default=512, help="Output width (default: 512)")
    vis_parser.add_argument("--height", type=int, default=512, help="Output height (default: 512)")
    vis_parser.set_defaults(func=cmd_visualize)

    # Overlay command
    overlay_parser = subparsers.add_parser(
        "overlay",
        help="Overlay tilemap colors on an existing image",
        description="Create a comparison overlay of tilemap colors on an existing image.",
    )
    overlay_parser.add_argument("image", type=Path, help="Path to existing image")
    overlay_parser.add_argument("tilemap", type=Path, help="Path to tilemap JSON file")
    overlay_parser.add_argument("-o", "--output", type=Path, help="Output image path")
    overlay_parser.add_argument("--alpha", type=float, default=0.4, help="Overlay opacity (default: 0.4)")
    overlay_parser.set_defaults(func=cmd_overlay)

    args = parser.parse_args()
    args.func(args)


if __name__ == "__main__":
    main()
